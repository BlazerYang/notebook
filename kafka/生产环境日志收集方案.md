# 生产环境日志收集方案

## 背景
1. 线上环境机器较多，，问题排查时查找日志并不方便
2. 容器化方案时使用xtermjs连接非常稳定

## 方案
容器中集成有kafka的agent，这样的话可以申请一个topic，将日志内容发送至topic中。然后启动一个logstash服务消费该topic中的日志，解析后存储至ES中，然后在Kibana中查看即可

## Q&A

### logstash是什么？
Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的 “存储库” 中
[Logstash中文官网](https://www.elastic.co/cn/products/logstash)

#### "利用 Grok 从非结构化数据中派生出结构", Grok是什么？
Grok是一个包含若干预定义规则的正则匹配引擎，用于从文本中匹配出数据

#### 如果输入是若干行 为一条日志记录（普通是一行一个），应该如何匹配出对应的数据？
